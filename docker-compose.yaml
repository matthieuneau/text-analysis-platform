services:
  gateway:
    build:
      context: .
      dockerfile: services/gateway/Dockerfile
      target: development
    ports:
      - "8000:8000"
    depends_on:
      preprocessing:
        condition: service_healthy
      sentiment_analysis:
        condition: service_healthy
      summarization:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - app-network
    env_file:
      - .env
    labels:
      logging: "promtail"
      logging_jobname: "gateway"
    
  preprocessing:
    build:
      context: .
      dockerfile: services/preprocessing/Dockerfile
      target: development
    # No ports exposed - only internal communication
    ports:
      - "8001:8000"  # For local testing
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      retries: 5
      timeout: 5s
      interval: 10s
      start_period: 10s
    env_file:
      - services/preprocessing/.env
    labels:
      logging: "promtail"
      logging_jobname: "preprocessing"

  sentiment_analysis:
    build:
      context: .
      dockerfile: services/sentiment_analysis/Dockerfile
      target: development
    # No ports exposed - only internal communication
    volumes:
      - sentiment-models:/root/.cache/huggingface  # HF default cache location
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      retries: 5
      timeout: 5s
      interval: 10s
      start_period: 60s   # Loading ML model takes some time
    labels:
      logging: "promtail"
      logging_jobname: "sentiment_analysis"

  summarization:
    build:
      context: .
      dockerfile: services/summarization/Dockerfile
      target: development
    # No ports exposed - only internal communication
    volumes:
      - summarization-models:/root/.cache/huggingface
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      retries: 5
      timeout: 5s
      interval: 10s
      start_period: 60s   # Loading ML model takes some time
    networks:
      - app-network
    labels:
      logging: "promtail"
      logging_jobname: "summarization"

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./services/gateway/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - app-network

  auth:
    build:
      context: .
      dockerfile: services/auth/Dockerfile
      target: development
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - app-network
    labels:
      logging: "promtail"
      logging_jobname: "auth"

# Loki for log storage
  loki:
    image: grafana/loki:latest
    ports:
      - "3100:3100"
    volumes:
      - loki-data:/tmp/loki
    # No command - use built-in default config
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:3100/ready"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - app-network

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    volumes:
      - grafana-data:/var/lib/grafana
    env_file:
      - services/grafana/.env
    depends_on:
      loki:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:3000/api/health"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - app-network

  # Promtail for log shipping
  promtail:
    image: grafana/promtail:latest
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - ./promtail-config.yml:/etc/promtail/config.yml
    # No command - use built-in default config
    ports:
      - "9080:9080"
    depends_on:
      loki:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "promtail", "-version"]
      interval: 10s
      timeout: 30s
      retries: 5
      start_period: 30s
    labels:
      logging: "promtail"
      logging_jobname: "promtail"
    networks:
      - app-network

  k6:
    image: grafana/k6:latest
    command: run /k6-tests/register-users.js
    volumes:
      - ./k6-tests:/k6-tests
    depends_on:
      gateway:
        condition: service_healthy
      prometheus:
        condition: service_healthy
      auth:
        condition: service_healthy
    environment:
      - K6_PROMETHEUS_RW_SERVER_URL=http://prometheus:9090/api/v1/write
      - K6_PROMETHEUS_RW_TREND_AS_NATIVE_HISTOGRAM=true
    profiles:
      - load-test  # Only run when explicitly requested
    networks:
      - app-network
    

networks:
  app-network:
    driver: bridge
  
volumes:
  prometheus-data:
  summarization-models:
  sentiment-models:
  loki-data:
  grafana-data:
