services:
  gateway:
    build:
      context: .
      dockerfile: services/gateway/Dockerfile
      target: development
    ports:
      - "8000:8000"
    depends_on:
      preprocessing:
        condition: service_healthy
      sentiment_analysis:
        condition: service_healthy
      summarization:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    networks:
      - app-network
    env_file:
      - .env
    
  preprocessing:
    build:
      context: .
      dockerfile: services/preprocessing/Dockerfile
      # target: production
    # No ports exposed - only internal communication
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      retries: 5
      timeout: 5s
      interval: 10s
      start_period: 10s

  sentiment_analysis:
    build:
      context: .
      dockerfile: services/sentiment_analysis/Dockerfile
      target: development
    # No ports exposed - only internal communication
    volumes:
      - sentiment-models:/root/.cache/huggingface  # HF default cache location
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      retries: 5
      timeout: 5s
      interval: 10s
      start_period: 60s   # Loading ML model takes some time

  summarization:
    build:
      context: .
      dockerfile: services/summarization/Dockerfile
      target: development
    # No ports exposed - only internal communication
    volumes:
      - summarization-models:/root/.cache/huggingface
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      retries: 5
      timeout: 5s
      interval: 10s
      start_period: 60s   # Loading ML model takes some time
    networks:
      - app-network

  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./services/gateway/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus-data:/prometheus
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:9090/-/healthy"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - app-network

  auth:
    build:
      context: .
      dockerfile: services/auth/Dockerfile
      target: development
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 10s
    networks:
      - app-network

  k6:
    image: grafana/k6:latest
    command: run /k6-tests/register-users.js
    volumes:
      - ./k6-tests:/k6-tests
    depends_on:
      gateway:
        condition: service_healthy
      prometheus:
        condition: service_healthy
      auth:
        condition: service_healthy
    environment:
      - K6_PROMETHEUS_RW_SERVER_URL=http://prometheus:9090/api/v1/write
      - K6_PROMETHEUS_RW_TREND_AS_NATIVE_HISTOGRAM=true
    profiles:
      - load-test  # Only run when explicitly requested
    networks:
      - app-network
    

networks:
  app-network:
    driver: bridge
  
volumes:
  prometheus-data:
  summarization-models:
  sentiment-models:
    
    
